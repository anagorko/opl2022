{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a90c4f40",
   "metadata": {},
   "source": [
    "# Drugi projekt. \n",
    "\n",
    "## Gry Stackelberga\n",
    "\n",
    "W gry Stackelberga gra lider (obrońca), który wybiera swoją strategię (mieszaną) jako pierwszy i naśladowcy (atakujący), którzy wybierają swoje strategie po poznaniu strategii lidera. Nie są to gry o sumie zerowej: lider i naśladowcy mają swoje własne macierze wypłat.\n",
    "    \n",
    "Rozważmy przykład - grę z jednym naśladowcą. Macierz wypłat to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7512e381",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{|c|c|c|}\n",
    "\\hline & c & d \\\\\n",
    "\\hline a & 2,1 & 4,0\\\\\n",
    "\\hline b & 1,0 & 3,2\\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550dfce2",
   "metadata": {},
   "source": [
    "Lider gra wierszami. Jego ruchy to `a` i `b`. \n",
    "Naśladowca gra kolumnami. \n",
    "Jego ruchy to `c` i `d`.\n",
    "Pierwsza z liczb w macierzy wypłat to wypłata lidera. Druga to wypłata naśladowcy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1f5ed7",
   "metadata": {},
   "source": [
    "Jedyną równowagą Nasha (przy jednoczesnym wyborze strategii) w tej grze jest zagranie `a` przez lidera i `c` przed naśladowcę, co daje liderowi wypłatę równą $2$.\n",
    "\n",
    "Jeżeli jednak lider wybierze swoją strategię jako pierwszy i będzie grał `a` i `b` z prawdopodobieństwem $\\frac 12$, to naśladowca zmieni swoją strategię na `d`, powiększając (oczekiwaną) wypłatę lidera do $3\\frac 12$.\n",
    "\n",
    "W grze Stackelberga naśladowca zna mieszaną strategię lidera, ale nie zna konkretnego ruchu przez niego wybranego."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c01e63",
   "metadata": {},
   "source": [
    "## Bayesowskie gry Stackelberga\n",
    "\n",
    "W bayesowskiej grze Stackelberga dopuszczamy $N$ różnych naśladowców i jednego lidera.\n",
    "Podczas rozgrywki jako pierwszy strategię wybiera lider, następnie swoje strategie wybierają naśladowcy.\n",
    "Rozgrywka jest pomiędzy liderem a jednym z naśladowców (nazwijmy go $n$), wybieranym z puli z prawdopodobieństwem $p_n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db6fbdf",
   "metadata": {},
   "source": [
    "Rozszerzając poprzedni przykład\n",
    "$$\n",
    "\\begin{array}{|c|c|c|}\n",
    "\\hline & c & d \\\\\n",
    "\\hline a & 2,1 & 4,0\\\\\n",
    "\\hline b & 1,0 & 3,2\\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$\n",
    "możemy dodać drugiego naśladowcę\n",
    "$$\n",
    "\\begin{array}{|c|c|c|}\n",
    "\\hline & c' & d' \\\\\n",
    "\\hline a & 1,1 & 2,0\\\\\n",
    "\\hline b & 0,1 & 3,2\\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$\n",
    "Każdy z naśladowców pojawia się z prawdopodobieństwem $\\frac 12$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63f8d80",
   "metadata": {},
   "source": [
    "## Wyznaczanie optymalnej strategii za pomocą MILP\n",
    "\n",
    "Zapiszemy problem wyznaczania optymalnej strategii lidera jako problem całkowitoliczbowy.\n",
    "Zaczniemy od naturalnego sformułowania problemu z nieliniowymi (kwadratowymi) warunkami.\n",
    "Optymalna strategia lidera zakłada, że naśladowcy dobierają optymalne strategie do jego strategii.\n",
    "W takim przypadku naśladowcy zawsze mogą wybrać strategie czyste - zawsze jeden z ruchów będzie nie gorszy od pozostałych.\n",
    "\n",
    "Zbiór typów naśladowców oznaczamy przez $L$.\n",
    "Prawdopodobieństwo gry przeciwko naśladowcy typu $l \\in L$ oznaczamy przez $p^l$.\n",
    "Jest ono z góry dane.\n",
    "\n",
    "Przez $x$ oznaczamy strategię lidera. Liczba  $x_i$ oznacza prawdopodobieństwo zagrania ruchu $i$ przez lidera.\n",
    "Strategię naśladowcy typu $l \\in L$ oznaczamy przez $q^l$.\n",
    "Przez $R^l$ i $C^l$ oznaczamy wypłaty dla lidera i naśladowcy w grze pomiędzy liderem a naśladowcą typu $l$.\n",
    "Przez $X$ i $Q$ oznaczamy możliwe ruchy (strategie czyste) lidera i naśladowców.\n",
    "\n",
    "Niech $M$ oznacza (dostatecznie) dużą liczbę."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf821e2",
   "metadata": {},
   "source": [
    "Strategię lidera możemy wyznaczyć rozwiązując następujący problem.\n",
    "\n",
    "$$\n",
    "\\max_{x,q,a} \\sum_{i \\in X} \\sum_{l \\in L} \\sum_{j \\in Q} p^l R^l_{ij} x_i q^l_j\n",
    "$$\n",
    "pod warunkami\n",
    "$$\n",
    "\\sum_{i\\in X} x_i = 1\n",
    "$$\n",
    "$$\n",
    "\\sum_{j \\in Q} q^l_j = 1\n",
    "$$\n",
    "$$\n",
    "0 \\leq (a^l - \\sum_{i \\in X} c^l_{ij} x_i) \\leq (1 - q^l_j) M\n",
    "$$\n",
    "$$\n",
    "x_i \\in [0, 1]\n",
    "$$\n",
    "$$\n",
    "q^l_j \\in \\{0,1\\}\n",
    "$$\n",
    "$$\n",
    "a^l \\in \\mathbb{R}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4fcc23",
   "metadata": {},
   "source": [
    "## Zadanie - część teoretyczna\n",
    "\n",
    "Wyjaśnij dlaczego rozwiązanie optymalne powyższego problemu wyznacza strategię optymalną lidera. Co to jest $a^l$ w problemie?\n",
    "\n",
    "Zwróć uwagę, że problem nie jest liniowy: w funkcji celu mamy iloczyny $x_i q^l_j$ a zmienne $q^l_j$ są binarne.\n",
    "\n",
    "Następnie udowodnij, że następująca *linearyzacja* (zmienne binarne pozostają) problemu jest poprawna:\n",
    "$$\n",
    "\\max_{q,z,a} \\sum_{i\\in X}\\sum_{l \\in L}\\sum_{j \\in Q} p^l R^l_{ij} z^l_{ij}\n",
    "$$\n",
    "pod warunkami\n",
    "$$\n",
    "\\sum_{i \\in X} \\sum_{j \\in Q} z^l_{ij} = 1\n",
    "$$\n",
    "$$\n",
    "\\sum_{j \\in Q} z^l_{ij} \\leq 1\n",
    "$$\n",
    "$$\n",
    "q^l_j \\leq \\sum_{i\\in X} z^l_{ij} \\leq 1\n",
    "$$\n",
    "$$\n",
    "\\sum_{j \\in Q}q^l_j = 1\n",
    "$$\n",
    "$$\n",
    "0 \\leq (a^l - \\sum_{i \\in X} C^l_{ij} (\\sum_{h \\in Q} z^l_{ih})) \\leq (1 - q^l_j) M\n",
    "$$\n",
    "$$\n",
    "\\sum_{j \\in Q} z^l_{ij} = \\sum_{j \\in Q} z^1_{ij}\n",
    "$$\n",
    "$$\n",
    "z^l_{ij} \\in [0, 1]\n",
    "$$\n",
    "$$\n",
    "q^l_j \\in \\{0,1\\}\n",
    "$$\n",
    "$$\n",
    "a^l \\in \\mathbb{R}\n",
    "$$\n",
    "\n",
    "Jest to tak zwany algorytm DOBSS, pochodzący z pracy \n",
    "\n",
    "`Paruchuri et al., Efficient Algorithms to Solve Bayesian Stackelberg Games for Security\n",
    "Applications, AAAI 2008.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7632c27b",
   "metadata": {},
   "source": [
    "## Zadanie - część praktyczna\n",
    "\n",
    "Gry Stackelberga w ostatnich latach były stosowane w wielu kontekstach praktycznych. Poczynając od ochrony lotniska LAX w Los Angeles, poprzez optymalizację działań patroli USCG (U.S. Coastal Guard) po ochronę dzikich zwierząt przed kłusownikami w rezerwatach i wyłapywanie w metrze pasażerów na gapę.\n",
    "\n",
    "Przykład z pracy (cytuję sekcję 4.3)\n",
    "\n",
    "`Pita et al., Deployed ARMOR Protection: The Application of a Game\n",
    "Theoretic Model for Security at the Los Angeles\n",
    "International Airport, AAMAS 2008.`\n",
    "\n",
    "---\n",
    "\n",
    "> We now illustrate how the security problems set forth by LAWA police, i.e. where and when to deploy checkpoints and canines, can be cast in terms of a Bayesian Stackelberg game. We focus on the checkpoint problem for illustration, but the case of the canine problem is similar. At LAX, there are a specific number of inbound roads on which to set up checkpoints, say roads 1 through n, and LAWA police have to pick a subset of those roads to place checkpoints on prior to adversaries selecting which roads to attack. We assume that there are m different types of adversaries, each with different attack capabilities, planning constraints, and financial ability. Each adversary type observes the LAWA-police check-point policy and then decides where to attack. Since adversaries can observe the LAWA police policy before deciding their actions, this situation can be modeled via a Stackelberg game with the police as the leader.\n",
    ">\n",
    "> In this setting the set X of possible actions for LAWA police is the set of possible checkpoint combinations. If, for instance, LAWA police were setting up one checkpoint then $X = \\{ 1, . . . , n \\}$. If LAWA police were setting up a combination of two checkpoints, then $X = \\{(1, 2), (1, 3)...(n − 1, n)\\}$, i.e. all combinations of two checkpoints. Each adversary type $l \\in L = \\{1, . . . , m\\}$ can decide to attack one of the n roads or maybe not attack at all (none), so its set of actions is $Q = \\{1, . . . , n, none\\}$. If LAWA police select\n",
    "road i to place a checkpoint on and adversary type $l \\in L$ selects road j to attack then the agent receives a reward $R^l_{ij}$ and the adversary receives a reward $C^l_{ij}$. These reward values vary based on three considerations: \n",
    ">\n",
    ">(i) the chance that the LAWA police check-point will catch the adversary on a particular inbound road; \n",
    ">\n",
    ">(ii) the damage the adversary will cause if it attacks via a particular in-\n",
    "bound road; \n",
    ">\n",
    ">(iii) type of adversary, i.e. adversary capability. \n",
    ">\n",
    ">If LAWA police catch the adversary when i = j we make $R^l_{ij}$ a large positive value and $C^l_{ij}$ a large negative value. However, the probability of catching the adversary at a checkpoint is based on the volume of traffic through the checkpoint (significant traffic will increase the difficulty of catching the adversary), which is an input to the system. If the LAWA police are unable to catch the adversary, then the adversary may succeed, i.e. we make $R^l_{ij}$ a large negative value and $C^l_{ij}$ a large positive value. Certainly, if the adversary attacks via an inbound road where no checkpoint was set up, there is no chance that the police will catch the adversary. The magnitude of $R^l_{ij}$ and $C^l_{ij}$ vary based on the adversary’s potential target, given the road from which the adversary attacks. Some roads lead to higher valued targets for the adversary than others. The game is not a zero sum game however, as even if the adversary is caught, the adversary may benefit due to publicity.\n",
    ">\n",
    ">The reason we consider a Bayesian Stackelberg game is because LAWA police face multiple adversary types. Thus, differing values of the reward matrices across the different adversary types $l \\in L$ represent the different objectives and valuations of the different attackers (e.g. smugglers, criminals, terrorists). For example, a hard-\n",
    "core, well-financed adversary could inflict significant damage on LAX; thus, the negative rewards to the LAWA police are much higher in magnitude than an amatuer attacker who may not have sufficient resources to carry out a large-scale attack. Currently we model two types of adversary LAWA may face. A 20-80 split of probability implies that while there is a 20% chance that the LAWA police face the former type of adversary, there is an 80% chance\n",
    "that they face an amatuer attacker. Our experimental data provides detailed results about the sensitivity of our algorithms to the probability distributions over different adversary types. Given these two adversary types the largest game we have constructed, which was done for canine deployment, consisted of 784 actions for the LAWA\n",
    "police (when multiple canine units were active) for the eight possible terminals within the airport and 9 actions per adversary type (one for a possible attack on each terminal, and one for none).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bbe0bc",
   "metadata": {},
   "source": [
    "W części praktycznej Twoim zadaniem jest zaproponowanie scenariusza zastosowania gry Stackelberga: określenie lidera i naśladowców oraz ich macierzy wypłat, a następnie policzynie optymalnej strategii dla lidera.\n",
    "Na wyższe oceny mile widziana jest kreatywność w sformułowaniu problemu. Na zaliczenie wystarczy odwtorzyć powyższy scenariusz z lotniska LAX."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fd8fc3",
   "metadata": {},
   "source": [
    "## Forma rozwiązania i termin\n",
    "\n",
    "Rozwiązanie powinno zawierać raport zawierający opis problemu, szczegółowy opis przyjętego sposobu rozwiązania, arkusz zawierający wykonane obliczenia oraz uzyskane wyniki (część praktyczna) oraz dowód poprawności (część teoretyczna).\n",
    "\n",
    "Rozwiązania należy wysyłać e-mailem do prowadzącego ćwiczenia (w grupie piątkowej z kopią do wykładowcy) do 19 czerwca do godz. 23:59. W przypadku problemu z dotrzymaniem terminu proszę o wcześniejszy kontakt z wykładowcą (zanim termin minie!).\n",
    "\n",
    "Zaliczenie podczas ustnego egzaminu w trakcie sesji. Na egzamin trzeba przygotować prezentację (maksymalnie 10 minut, należy przygotować slajdy) na temat uzyskanych wyników i wykorzystanych metod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b19049f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.5",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
